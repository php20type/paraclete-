[03-Aug-2023 18:37:40 Pacific/Midway] "You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https:\/\/platform.openai.com\/account\/api-keys."
[03-Aug-2023 18:38:02 Pacific/Midway] "You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https:\/\/platform.openai.com\/account\/api-keys."
[03-Aug-2023 18:38:50 Pacific/Midway] "You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https:\/\/platform.openai.com\/account\/api-keys."
[04-Aug-2023 02:42:45 America/New_York] "You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https:\/\/platform.openai.com\/account\/api-keys."
[11-Aug-2023 10:13:26 America/New_York] "Bad gateway."
[11-Aug-2023 10:20:04 America/New_York] "This model's maximum context length is 4097 tokens. However, your messages resulted in 18496 tokens. Please reduce the length of the messages."
[11-Aug-2023 10:20:20 America/New_York] "This model's maximum context length is 4097 tokens. However, your messages resulted in 18506 tokens. Please reduce the length of the messages."
[11-Aug-2023 10:30:37 America/New_York] "This model's maximum context length is 4097 tokens. However, your messages resulted in 5019 tokens. Please reduce the length of the messages."
[11-Aug-2023 10:45:38 America/New_York] "Bad gateway."
[13-Sep-2023 09:18:12 America/New_York] "This model's maximum context length is 4097 tokens. However, your messages resulted in 5311 tokens. Please reduce the length of the messages."
[13-Sep-2023 09:18:35 America/New_York] "This model's maximum context length is 4097 tokens. However, your messages resulted in 5323 tokens. Please reduce the length of the messages."
[13-Sep-2023 09:20:04 America/New_York] "This model's maximum context length is 4097 tokens. However, your messages resulted in 5333 tokens. Please reduce the length of the messages."
[13-Sep-2023 09:24:50 America/New_York] "This model's maximum context length is 4097 tokens. However, your messages resulted in 5344 tokens. Please reduce the length of the messages."
[25-Sep-2023 01:30:57 America/New_York] "This model's maximum context length is 4097 tokens. However, your messages resulted in 4610 tokens. Please reduce the length of the messages."
[25-Sep-2023 01:40:28 America/New_York] "This model's maximum context length is 4097 tokens. However, your messages resulted in 4620 tokens. Please reduce the length of the messages."
